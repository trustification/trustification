= Post installation tasks

== Configuring the CVE import job

By default, a `CronJob` will be created which imports the full CVE project data. This job is scheduled by default to
running during the night. An initial import will take several hours. Afterwards only changes will be applied.

The initial job can run once by executing:

[source,bash]
----
kubectl -n trustification create job --from=cronjob/v11y-walker v11y-walker-initial
----

It is also possible to limit the data the job will import. This can be done using the following variables in the
Helm chart:

TIP: As filenames use the CVE ID, and CVE IDs are structured in the form of `CVE-<year>-`, this can be used to limit
the import based on years.

IMPORTANT: Enabling the prefix filter will disable the delta import.

[source,yaml]
----
modules:
  v11yWalker:
    onlyPrefixes:
      - "CVE-2023-"
      - "CVE-2024-"
----

== Adding a CSAF data source

To pull in CSAF data (advisories, VEX) into the system, you can set up a cron job, fetching and uploading
new data from a trusted CSAF provider.

To do this, you need to:

* Add this to the configuration of the values file
* Re-run the Helm chart deployment

To add the Red Hat CSAF documents, add the following section to the values file:

[source,yaml]
----
modules:
  vexinationWalker:
    sources:
      redhat: # <1>
        url: https://www.redhat.com/.well-known/csaf/provider-metadata.json # <2>
        acceptV3Signatures: true # <3>
        ignoreDistributions: # <4>
          - https://access.redhat.com/security/data/csaf/v2/advisories/
        job:
          schedule: "0 * * * *" # <5>
----
<1> The name of the source to add, this must be unique for all CSAF sources and is the basis for the created Kubernetes resources
<2> The URL to the CSAF source
<3> An option to still support GPG v3 signatures
<4> A list of distributions to ignore from the provider metadata
<5> A Kubernetes cron job expression when the job should be scheduled

== Adding an SBOM source

To pull in SBOMs from a remote source, you can set up a cron job, fetching and uploading new data from source
that follows a certain convention:

* List all available documents in a CSV document named `changed.csv`, relative to the base URL.
+
The format must be a CSV (comma separated values) file, having to columns and no header. The first column is the
location of the SBOM relative to the base URL, the second column is the last modified timestamp in RFC 3339
format. For example:
+
[source,csv]
----
"spdx/quarkus-bom-3.2.9.Final-redhat-00003.json.bz2","2024-02-04T14:00:11+00:00"
"spdx/quarkus-bom-2.13.8.SP2-redhat-00001.json.bz2","2024-02-04T14:00:04+00:00"
----
* If documents are signed with a GPG key, that key must be publicly available through HTTPS
* SBOMs must be available in JSON format, and maybe BZip2 compressed

To add the Red Hat SBOM documents, add the following section to the values file:

[source,yaml]
----
modules:
  bombasticWalker:
    sources:
      redhat: # <1>
        url: https://access.redhat.com/security/data/sbom/beta/ # <2>
        signingKeyUrl: https://access.redhat.com/security/data/97f5eac4.txt#77E79ABE93673533ED09EBE2DCE3823597F5EAC4 # <3>
        acceptV3Signatures: true # <4>
        fixLicenses: true # <5>
        job:
          schedule: "0 * * * *" # <6>
----
<1> The name of the source to add, this must be unique for all SBOM sources and is the basis for the created Kubernetes resources
<2> The base URL of the SBOM storage
<3> The public GPG key the documents have been signed with. The fragment part of the URL is the key ID.
<4> An option to still support GPG v3 signatures
<5> If invalid SPDX licenses should be replaced with `NOASSERTION` when importing
<6> A Kubernetes cron job expression when the job should be scheduled

== Adding some branding

It is possible to change some of the visual aspects of the console. This consists of two aspects:

* Overriding some of the assets
* Injecting custom HTML content in some extension points

Overriding some of the assets can be done by mounting a `ConfigMap` into the container of the `spog-ui` deployment.
This mechanism can also be used to add a small set of assets. For more and bigger assets being used with the HTML
snippets, it may be required to serve them on a dedicated endpoints for assets.

Injecting custom HTML content can be achieved by creating a custom `spog-ui.yaml` configuration file. It is recommended
to create a copy of the
https://github.com/trustification/trustification/blob/main/spog/api/src/config/default.yaml[default file], and start
customizing it. The JSON schema describing the file can help identifying places for customization.

=== Branding Helm Chart

There is an example Helm chart, which can help create a custom branding chart. The chart itself is just considered
a blueprint, so it is recommended to copy and alter it according to your needs. It can be found here: https://github.com/trustification/trustification/tree/main/deploy/k8s/charts/trustification-branding

Put the branding assets into the `files/branding` folder to have them served by the `spog-ui` deployment. Then
update the UI configuration file `files/spog-ui.yaml`. Afterwards, install or update the Helm chart.

To have the Trustification use these resources, you will need to update the values file of the Trustification
deployment and re-apply it. Ensure the following values are set:

[source,yaml]
----
include::../examples/values-branding.yaml[]
----

As HTML snippets it is possible to inject kind of content as long as it is wrapped in a single root element. Styling
of content can be done by using the PatternFly CSS classes, which are already part of the page. It is also possible to
 navigate to a different page without actually reloading it. The following snippet shows an example using a button:

[source,html]
----
<a
  class="pf-v5-c-button pf-m-primary pf-m-display-lg" type="button"
  onclick="window.wasmBindings.spogNavigateTo('/scanner'); return false;" <1>
>Scan SBOM</a>
----
<1> JavaScript event handler to navigate to a different page

== Tweaking index distribution

Once documents have been uploaded to one of the different Trustification services, an indexing process will pick those
changes up. It will extract relevant information from the uploaded document and store this into an index, so that it is
available for the search functionality.

There is a time between the uploading process has finished, and the index was made available to the API endpoints
though. This means that after uploading, you will not be able to find this document using the search functionality until
the indexing process has been completed and distributed to the search endpoint processes.

=== Configuration

There is a scheduled delay for distributing an updated index to the API endpoints. This value has some reasonable
default, which can be changes in the values file using the following fields:

[source,yaml]
----
bombastic:
  syncInterval: 5m

vexination:
  syncInterval: 5m

v11y:
  syncInterval: 30m
----

[TIP]
.Duration format
====
The format of the interval duration is the "humantime" format. For example: 30 seconds is written as `30s`, five minutes
is written as `5m`.

For more information see: <https://docs.rs/humantime/latest/humantime/fn.parse_duration.html>.
====

NOTE: After changing the values in values file, be sure to re-apply the Helm chart.

=== Choosing a reasonable interval

Choosing a reasonable interval depends on various factors. On the one side, the more often the indexes are
 synchronized, the sooner a search result will be visiable to the user. On the other side, the more frequent indexes
are being synchronized, the more bytes will be transferred. And transferred bytes might add to your AWS bill.

== Enabling ingestion report

During ingestion, jobs can generate reports regarding warnings and errors encountered during the process.
The report is turned off by default. Tu turn it on, you need to enable it and set authentication details im the
values file (values-report-userpass.yaml).

[source,yaml]
----
report:
  enabled: true
  auth:
    username: admin
    password: admin123456
----

Alternately, you can create an authentication secret manually, like

[source,bash]
----
htpasswd -c .htpasswd admin
kubectl create secret generic report-server-auth --from-file=.htpasswd
----

And reference that secret in the report configuration (values-report-secret.yaml)

[source,yaml]
----
report:
  enabled: true
  auth:
    secretRef:
      name: report-server-auth
      key: .htpasswd
----

After successful chart deployment, reports should be available at the URL of the appropriate route.

[source,bash]
----
oc get route -o jsonpath='{"https://"}{range .items[?(@.spec.to.name=="report-server")]}{.spec.host}{"\n"}{end}'
----
